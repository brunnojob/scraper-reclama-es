#  Scraper Organizado de ReclamaÃ§Ãµes de TI

Sistema avanÃ§ado de scraping com organizaÃ§Ã£o em pastas e configuraÃ§Ã£o externa.

## Como Executar

### MÃ©todo Mais FÃ¡cil
```bash
# Clique duas vezes no arquivo:
run_organized.bat
```

### Pelo Terminal
```bash
python organized_scraper.py
```

## Estrutura de Pastas Criadas

```
project/
â”œâ”€â”€ sites_data/           # Dados especÃ­ficos de cada site
â”‚   â”œâ”€â”€ reclame_aqui/
â”‚   â”œâ”€â”€ consumidor_gov/
â”‚   â”œâ”€â”€ ebit/
â”‚   â”œâ”€â”€ trustpilot/
â”‚   â”œâ”€â”€ complaints_board/
â”‚   â””â”€â”€ sitejabber/
â”œâ”€â”€ problems_found/       # Problemas organizados por severidade
â”‚   â”œâ”€â”€ critical/         # ğŸ”´ Problemas crÃ­ticos
â”‚   â”œâ”€â”€ high/            # ğŸŸ  Problemas altos
â”‚   â”œâ”€â”€ medium/          # ğŸŸ¡ Problemas mÃ©dios
â”‚   â””â”€â”€ low/             # ğŸŸ¢ Problemas baixos
â”œâ”€â”€ reports/             # RelatÃ³rios finais
â””â”€â”€ logs/               # Logs de execuÃ§Ã£o
```

## ConfiguraÃ§Ã£o de Sites

### Arquivo `sites_config.txt`

Edite este arquivo para:
- Adicionar novos sites
- Desabilitar sites especÃ­ficos
- Configurar URLs de busca

**Formato:**
```
nome_site|url_base|url_busca|ativo(sim/nao)|usa_selenium(sim/nao)
```

**Exemplo:**
```
reclame_aqui|https://www.reclameaqui.com.br|https://www.reclameaqui.com.br/busca|sim|sim
novo_site|https://exemplo.com|https://exemplo.com/search|nao|nao
```

## CategorizaÃ§Ã£o de Problemas

### Por Severidade:
- ğŸ”´ **CRÃTICOS**: Sistema fora do ar, perda de dados, hacks
- ğŸŸ  **ALTOS**: Bugs, falhas, erros que impedem uso
- ğŸŸ¡ **MÃ‰DIOS**: LentidÃ£o, timeouts, carregamento
- ğŸŸ¢ **BAIXOS**: Problemas menores de usabilidade

### Por Palavras-chave:
- Sistema, bug, falha, erro, crash
- Suporte tÃ©cnico, servidor, seguranÃ§a
- Aplicativo, site, login, acesso
- E mais 25+ termos tÃ©cnicos

## Arquivos Gerados

### Por Site:
- `{site}_data_YYYYMMDD_HHMMSS.json` - Dados brutos
- `{site}_summary.csv` - Resumo para Excel

### Por Severidade:
- `critical_problems.txt` - Problemas crÃ­ticos
- `high_problems.txt` - Problemas altos
- `medium_problems.txt` - Problemas mÃ©dios
- `low_problems.txt` - Problemas baixos
- `severity_summary.txt` - Resumo geral

### RelatÃ³rios:
- `final_report_YYYYMMDD_HHMMSS.txt` - RelatÃ³rio completo
- `organized_complaints.db` - Banco de dados SQLite

## Funcionalidades AvanÃ§adas

### Sistema de PontuaÃ§Ã£o
- Cada problema recebe score de 0-100
- Bonus para palavras crÃ­ticas
- Filtragem automÃ¡tica por relevÃ¢ncia

### DetecÃ§Ã£o Inteligente
- Identifica tipo de problema
- Extrai nome da empresa
- Categoriza automaticamente

### OrganizaÃ§Ã£o AutomÃ¡tica
- Separa por site de origem
- Agrupa por severidade
- Gera estatÃ­sticas detalhadas

## PersonalizaÃ§Ã£o

### Adicionar Novo Site:
1. Abra `sites_config.txt`
2. Adicione linha: `nome|url_base|url_busca|sim|nao`
3. Execute o scraper

### Modificar Palavras-chave:
1. Edite `organized_scraper.py`
2. Modifique lista `self.ti_keywords`
3. Adicione termos especÃ­ficos

### Ajustar Severidade:
1. Modifique funÃ§Ã£o `categorize_problem()`
2. Adicione novos critÃ©rios
3. Personalize classificaÃ§Ã£o

## Exemplo de Uso

```python
# Executar scraping completo
scraper = OrganizedScraper()
scraper.run_scraping()

# Verificar resultados
# - Pasta sites_data/ terÃ¡ dados de cada site
# - Pasta problems_found/ terÃ¡ problemas por severidade
# - Pasta reports/ terÃ¡ relatÃ³rio final
```

## Problemas Comuns

**"Python nÃ£o reconhecido"**
- Instale Python de python.org
- Marque "Add to PATH"

**"Poucos resultados"**
- Sites podem bloquear scraping
- Ajuste delays no cÃ³digo
- Verifique sites_config.txt

**"Erro de SSL"**
- Normal em alguns sites
- Scraper continua funcionando

## Suporte

1. Verifique pasta `logs/` para erros
2. Consulte `reports/` para estatÃ­sticas
3. Edite `sites_config.txt` para ajustes

---

**Sistema criado para anÃ¡lise Ã©tica de reclamaÃ§Ãµes pÃºblicas de TI**
